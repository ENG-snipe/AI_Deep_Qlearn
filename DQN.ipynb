{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but Discrete(100) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: TwoLinkArmEnv()])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Initialize DQN agent\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\dqn\\dqn.py:104\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     78\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[DQNPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    103\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No action noise\u001b[39;49;00m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_initial_eps \u001b[38;5;241m=\u001b[39m exploration_initial_eps\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_final_eps \u001b[38;5;241m=\u001b[39m exploration_final_eps\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:110\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[BasePolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m=\u001b[39m buffer_size\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\stable_baselines3\\common\\base_class.py:180\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vec_normalize_env \u001b[38;5;241m=\u001b[39m unwrap_vec_normalize(env)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supported_action_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe algorithm only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_action_spaces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as action spaces \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_multi_env \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: the model does not support multiple envs; it requires \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma single vectorized environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gymnasium.spaces.discrete.Discrete'>,) as action spaces but Discrete(100) was provided"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "\n",
    "class TwoLinkArmEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(TwoLinkArmEnv, self).__init__()\n",
    "        self.link1_length = 1.0  # Length of the first link\n",
    "        self.link2_length = 1.0  # Length of the second link\n",
    "        self.max_angle = np.pi  # Maximum angle (in radians)\n",
    "        \n",
    "        # Action space: discrete action space of 10 levels per joint (discretized joint angles)\n",
    "        self.num_actions = 10\n",
    "        self.action_space = spaces.Discrete(self.num_actions * self.num_actions)\n",
    "\n",
    "        # Observation space: two continuous values for joint angles (theta1, theta2)\n",
    "        self.observation_space = spaces.Box(low=-self.max_angle, high=self.max_angle, shape=(2,), dtype=np.float32)\n",
    "\n",
    "        # Initial state: joint angles (theta1, theta2)\n",
    "        self.state = np.zeros(2, dtype=np.float32)\n",
    "\n",
    "        # Initialize the plot for visualization\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlim(-2, 2)\n",
    "        self.ax.set_ylim(-2, 2)\n",
    "        self.ax.set_aspect('equal')\n",
    "\n",
    "        # Discretize the joint angles\n",
    "        self.angle_values = np.linspace(-self.max_angle, self.max_angle, self.num_actions)\n",
    "\n",
    "    def step(self, action):\n",
    "        # Convert the discrete action to the corresponding joint angles\n",
    "        theta1_index = action // self.num_actions\n",
    "        theta2_index = action % self.num_actions\n",
    "        theta1 = self.angle_values[theta1_index]\n",
    "        theta2 = self.angle_values[theta2_index]\n",
    "        \n",
    "        self.state = np.array([theta1, theta2], dtype=np.float32)\n",
    "\n",
    "        # Calculate the end-effector position\n",
    "        x1 = self.link1_length * np.cos(self.state[0])\n",
    "        y1 = self.link1_length * np.sin(self.state[0])\n",
    "        x2 = x1 + self.link2_length * np.cos(self.state[0] + self.state[1])\n",
    "        y2 = y1 + self.link2_length * np.sin(self.state[0] + self.state[1])\n",
    "\n",
    "        # Calculate the reward (negative distance to origin for simplicity)\n",
    "        reward = -np.sqrt(x2**2 + y2**2)\n",
    "\n",
    "        # Termination condition (no termination in this case)\n",
    "        done = False\n",
    "        \n",
    "        return np.copy(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state to the initial position\n",
    "        self.state = np.zeros(2, dtype=np.float32)\n",
    "        return np.copy(self.state)\n",
    "\n",
    "    def render(self):\n",
    "        # Calculate the joint positions for visualization\n",
    "        x1 = self.link1_length * np.cos(self.state[0])\n",
    "        y1 = self.link1_length * np.sin(self.state[0])\n",
    "        x2 = x1 + self.link2_length * np.cos(self.state[0] + self.state[1])\n",
    "        y2 = y1 + self.link2_length * np.sin(self.state[0] + self.state[1])\n",
    "\n",
    "        # Plot the arm\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlim(-2, 2)\n",
    "        self.ax.set_ylim(-2, 2)\n",
    "        self.ax.set_aspect('equal')\n",
    "\n",
    "        # Plot the first link\n",
    "        self.ax.plot([0, x1], [0, y1], lw=4, color='blue')\n",
    "        # Plot the second link\n",
    "        self.ax.plot([x1, x2], [y1, y2], lw=4, color='green')\n",
    "\n",
    "        # Plot the end effector (tip of the second link)\n",
    "        self.ax.plot(x2, y2, 'ro')\n",
    "\n",
    "        # Display the plot\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)\n",
    "\n",
    "    def close(self):\n",
    "        # Close the environment\n",
    "        plt.close(self.fig)\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = DummyVecEnv([lambda: TwoLinkArmEnv()])\n",
    "\n",
    "# Initialize DQN agent\n",
    "model = DQN('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"dqn_two_link_arm\")\n",
    "\n",
    "# Evaluate the agent\n",
    "obs = env.reset()\n",
    "for _ in range(100):\n",
    "    action, _state = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
